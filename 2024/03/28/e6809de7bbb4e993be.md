---
title: 思维链
date: '2024-03-28T03:30:45+00:00'
status: publish
permalink: /2024/03/28/%e6%80%9d%e7%bb%b4%e9%93%be
author: 毛巳煜
excerpt: ''
type: post
id: 10740
category:
    - 人工智能
tag: []
post_format: []
wb_sst_seo:
    - 'a:3:{i:0;s:0:"";i:1;s:0:"";i:2;s:0:"";}'
hestia_layout_select:
    - sidebar-right
---
思维链提示综合指南-`CoT`
===============

什么是提示工程？
========

> **提示工程是`编写结构良好且精心制作的提示`的实践**，这些提示可以通过生成式 AI 模型更好地解释。
> 
> - 提示告诉 LLM 要执行什么任务以及要生成什么样的输出。它可以包含`指令、上下文、输入数据和输出指示器`。
> - 使用提示工程，我们可以使用 LLM 来执行各种任务，从简单的问答到复杂的创意文本生成。
> - 它基于一个涌现属性，即上下文学习，允许 LLM 从提示中学习。提示工程提高了 LLM 在手头任务上的性能。如前所述，它使用`零样本`、`少样本`、`主动`和`CoT`提示。
> 
>  [![](http://qiniu.dev-share.top/image/LLM/What_is_Prompt_Engineering-01.png)](http://qiniu.dev-share.top/image/LLM/What_is_Prompt_Engineering-01.png)

### Zero-shot Prompting 零样本提示

<div style="overflow:hidden; clear:both; width: 100%; height: 40px; position: relative;">- - - - - -

 <span style="position: absolute;top: 50%;left: 50%; transform: translate(-50%, -50%); background-color: white;">以下为隐藏内容</span> </div> - > 泛化：
  > 
  > 
  > - 模型的泛化能力指其对未见过数据的良好适应性，能够推广学到的知识而不仅限于训练数据。
  > - 泛化能力强的模型能够在各种情境中都表现良好，而不仅仅是在特定的训练数据上。
  > 
  >  过度拟合:
  > 
  > 
  > - 过度拟合是一个相反的概念，它指的是模型`过度适应训练数据`，而在`新数据上表现不佳`。
  > 
  >  总结：`泛化`就像是学习新东西后，能够在不同情境下灵活运用。而`过度拟合`则好比过于死记硬背，只在学习的那一套环境下表现好，到了新环境反而不行。有强泛化能力的模型就像是`灵活学习的好学生`，可以在各种情况下都表现出色。
- > Zero shot:
  > 
  > 
  > - Zero shot 就像是`一个学生`在`从未见过的考试中`能够凭借以前学到的一般性知识迅速作答，而不需要专门为这场考试进行特定的准备。它展示了模型具有推理和泛化到新任务的能力，无需针对特定任务进行额外的训练。就好比学生零准备、零提示，却能凭借自己的通用知识应对新的挑战一样。

### Few-shot Prompting 少样本提示

<div style="overflow:hidden; clear:both; width: 100%; height: 40px; position: relative;">- - - - - -

 <span style="position: absolute;top: 50%;left: 50%; transform: translate(-50%, -50%); background-color: white;">以下为隐藏内容</span> </div> - > 泛化：
  > 
  > 
  > - 模型的泛化能力指其对未见过数据的良好适应性，能够推广学到的知识而不仅限于训练数据。
  > - 泛化能力强的模型能够在各种情境中都表现良好，而不仅仅是在特定的训练数据上。
  > 
  >  过度拟合:
  > 
  > 
  > - 过度拟合是一个相反的概念，它指的是模型`过度适应训练数据`，而在`新数据上表现不佳`。
  > 
  >  总结：`泛化`就像是学习新东西后，能够在不同情境下灵活运用。而`过度拟合`则好比过于死记硬背，只在学习的那一套环境下表现好，到了新环境反而不行。有强泛化能力的模型就像是`灵活学习的好学生`，可以在各种情况下都表现出色。
- > Zero shot:
  > 
  > 
  > - Zero shot 就像是`一个学生`在`从未见过的考试中`能够凭借以前学到的一般性知识迅速作答，而不需要专门为这场考试进行特定的准备。它展示了模型具有推理和泛化到新任务的能力，无需针对特定任务进行额外的训练。就好比学生零准备、零提示，却能凭借自己的通用知识应对新的挑战一样。

### Active Prompting 主动提示

<div style="overflow:hidden; clear:both; width: 100%; height: 40px; position: relative;">- - - - - -

 <span style="position: absolute;top: 50%;left: 50%; transform: translate(-50%, -50%); background-color: white;">以下为隐藏内容</span> </div> - > 泛化：
  > 
  > 
  > - 模型的泛化能力指其对未见过数据的良好适应性，能够推广学到的知识而不仅限于训练数据。
  > - 泛化能力强的模型能够在各种情境中都表现良好，而不仅仅是在特定的训练数据上。
  > 
  >  过度拟合:
  > 
  > 
  > - 过度拟合是一个相反的概念，它指的是模型`过度适应训练数据`，而在`新数据上表现不佳`。
  > 
  >  总结：`泛化`就像是学习新东西后，能够在不同情境下灵活运用。而`过度拟合`则好比过于死记硬背，只在学习的那一套环境下表现好，到了新环境反而不行。有强泛化能力的模型就像是`灵活学习的好学生`，可以在各种情况下都表现出色。
- > Zero shot:
  > 
  > 
  > - Zero shot 就像是`一个学生`在`从未见过的考试中`能够凭借以前学到的一般性知识迅速作答，而不需要专门为这场考试进行特定的准备。它展示了模型具有推理和泛化到新任务的能力，无需针对特定任务进行额外的训练。就好比学生零准备、零提示，却能凭借自己的通用知识应对新的挑战一样。

什么是思维链提示？
=========

<div style="overflow:hidden; clear:both; width: 100%; height: 40px; position: relative;">- - - - - -

 <span style="position: absolute;top: 50%;left: 50%; transform: translate(-50%, -50%); background-color: white;">以下为隐藏内容</span> </div> - > 泛化：
  > 
  > 
  > - 模型的泛化能力指其对未见过数据的良好适应性，能够推广学到的知识而不仅限于训练数据。
  > - 泛化能力强的模型能够在各种情境中都表现良好，而不仅仅是在特定的训练数据上。
  > 
  >  过度拟合:
  > 
  > 
  > - 过度拟合是一个相反的概念，它指的是模型`过度适应训练数据`，而在`新数据上表现不佳`。
  > 
  >  总结：`泛化`就像是学习新东西后，能够在不同情境下灵活运用。而`过度拟合`则好比过于死记硬背，只在学习的那一套环境下表现好，到了新环境反而不行。有强泛化能力的模型就像是`灵活学习的好学生`，可以在各种情况下都表现出色。
- > Zero shot:
  > 
  > 
  > - Zero shot 就像是`一个学生`在`从未见过的考试中`能够凭借以前学到的一般性知识迅速作答，而不需要专门为这场考试进行特定的准备。它展示了模型具有推理和泛化到新任务的能力，无需针对特定任务进行额外的训练。就好比学生零准备、零提示，却能凭借自己的通用知识应对新的挑战一样。

参考资料
----

- [思路链提示综合指南 (mercity.ai)](https://www.mercity.ai/blog-post/guide-to-chain-of-thought-prompting)

限制
--

> CoT 推理是 LLM 的[一种涌现能力](https://web.stanford.edu/class/cs224v/lectures/jason-wei-emergence-talk-stanford.pdf)，可能是由于[将模型扩展到](https://arxiv.org/abs/2210.11416) 1000 亿个参数以上而产生的。它不会对较小的 LLM 的性能产生积极影响，只有在与这种规模的模型一起使用时才会产生性能提升。
> 
>  这有两个原因。
> 
> - 首先，较小的 LLM 无法产生既流畅又合乎逻辑的长链思维。这会导致性能低于标准提示。
> - 其次，CoT推理对于更复杂的问题更有效。它要求LLM能够确定解决问题所涉及的关键步骤，然后产生导致解决方案的思维链。较小的 LLM 可能无法像较大的 LLM 那样有效地做到这一点。
> 
>  CoT推理在大型LLM中出现的另一个原因可能是由于它们的预训练数据。较大的 LLM 通常在包含分步推理的海量数据集上进行训练，这可以帮助他们发展以思维链方式推理的能力。
> 
> - 对于CoT功能来说，指令遵循似乎不是必需的，因为`零样本`和`少样本CoT`推理是使用`未经微调`以遵循指令的LLM进行的。
> - 然而，指令遵循可能会提高 CoT 推理的质量。最终，需要更多的研究来确定大型LLM中出现CoT推理的确切原因。
> 
>  根据Wei等人的说法，**“`思维链仅在使用∼100B参数的模型时才会产生性能提升`”**。较小的模型编写了不合逻辑的思维链会导致精度比标准提示更差。通常，模型从思维链提示过程中获得性能提升的方式与模型的大小成比例。
> 
>  论文地址：https://arxiv.org/abs/2201.11903