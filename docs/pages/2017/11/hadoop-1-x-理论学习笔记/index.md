---
title: "Hadoop 1.x 理论学习笔记"
date: "2017-11-16"
categories: 
  - "大数据"
---

### Hadoop 是什么?

`开源的分布式存储+分布式计算平台`

* * *

### Hadoop 的组成

**包括两个核心组成:**

- **(1) HDFS: 分布式文件系统, 存储海量数据**
- **(2) MapReduce: 并行处理框架(分布式计算), 实现任务分解和调度**

* * *

### Hadoop 作用

`搭建大型数据仓库, PB级数据的存储 处理 分析 统计等业务`

* * *

### Hadoop 优势

- **(1) 高扩展**
- **(2) 低成本**
- **(3) 有成熟的开源的生态圈**

* * *

### HDFS 设计架构

- **块**
- **NameNode**
- **DataNode** `在HDFS里面所有的文件在存储的时候都是把文件切分成相同大小的块` `Hadoop 1.x 每个块的默认大小是64M` `Hadoop 2.x 每个块的默认大小是128M` `文件的备份和查找都是按照块来进行处理的`

* * *

### HDFS(分布式文件系统) 概念

`既然是分布式文件系统，肯定是主从模式，那么谁是主谁是从呢？` `HDFS 有两类节点 NameNode 和 DataNode` `NameNode是主， DataNode是从` `所以说HDFS是由一个NameNode和多个DataNode组成的。`

- **NameNode** **管理文件系统的命名空间，存放文件的元数据** **维护着文件系统的所有文件和目录，文件与数据块之间的映射** **记录着每个文件中的各个块所在数据节点的信息(这些信息会在DataNode启动的时候发送给DataNode)** **NameNode 是管理节点, 存放文件的源数据, 它包括两个部分**
    
    - **(1) 文件与数据块的映射表**
    - **(2) 数据块与数据节点的映射表**

* * *

- **DataNode 是HDFS的工作节点** `DataNode是用来存放真正的数据块` `存储并检索数据块，并且将它存储的这些数据块的列表发送给NameNode进行更新`

* * *

### HDFS 的特点

- **(1) 它将数据做了大量的冗余, 用三个备份来实现硬件上的容错 (允许运行在廉价机器上的容错)**
- **(2) 流式的数据访问 (一次写入,多次读取,无法修改,除非删掉块重新写)**
- **(3) 存储大文件 (如果是大量的小文件NameNode的负载压力会比较大, 所以它更适合存储大的文件)**

* * *

### 适用性和局限性

- **适合数据批量读写,吞量高**
- **不适合交互式应用 (例如数据库),因为它很难满足低延迟**
    
- **适合一次写入多次读取, 顺序读写**
    
- **不支持多个用户并发写相同文件**

### HDFS 总结

`HDFS是Hadoop分布式文件系统的简称,由若干台计算机组成,用于存放PB TB数量级以上的文件,每份文件可以有多个副本,所以HDFS是一个具有高冗余 高容错的文件系统.` `由于NameNode内存有限, 大量的小文件会给HDFS带来性能上的问题. 故HDFS更适合存放大文件, 对于大量的小文件, 可以采用压缩 合并小文件的优化策略. 例如:设置文件输入类型为 CombineFileInputFormat格式.`

* * *

* * *

* * *

## MapReduce 原理

### 什么是 MapReduce?

`将一个大的计算任务分成多个小的计算任务,由大任务到小任务的拆分就称为一个(Map)` `拆分成多个小任务之后,由多个节点进行并行执行` `执行之后在合并这些结果, 而合并的这个过程就是(Reduce)`

### MapReduce 的运行流程

#### 基本概念

- **Job & Task** `一个Job会被拆分成多个Task` `Task 又分为MapTask ReduceTask`
    
- **JobTracker** `作业调度` `分配任务, 监控任务执行进度` `监控TaskTracker的状态`
    
- **TaskTracket** `执行任务` `汇报任务状态`
    

* * *

### MapReduce的容错机制

`容错: 就是它允许在整个任务的执行过程中,这些 TaskTracket 可能中间会发生死机 发生故障等等都允许这些出错, 包括硬件出错!` **针对出错它有两个机制:**

- **(1) 重复执行** `默认情况下重复执行4次以后还是失败,将放弃执行.`
    
- **(2) 推测执行** `在整个任务执行过程种需要等到所有的Map端都计算完成之后Reduce端才会开始；` `但在这个过程中Map端可能会有某些 TaskTracket 节点算的特别特别慢, 在这个时候 JobTracket 会发现有一个节点计算的特别慢,相比其它节点慢的很多的时候,说明它已经出现了问题, 这个时候慢的节点继续执行, JobTracket 会在找一台 TaskTracket根它做同样的事情, 只要这两者有一个先计算完成, 就会终止掉另一个TaskTracket, 这样来保证整个任务执行的过程种不会因为各别的影响而导致执行效率变低!`
