---
title: "安装GPUstack"
date: "2025-05-23"
categories: 
  - "GPUstack"
---

# 安装GPUstack



## 系统

| 发行版           | 发行版代码 | 硬件架构 | 扩展架构 |
| ---------------- | ---------- | -------- | -------- |
| Ubuntu 22.04 LTS | ubuntu2204 | x86_64   | amd64    |



---



## 显卡信息

``` bash
Fri May 16 08:59:23 2025
╒═════════════════════════════════════════════════════════════════════════════╕
│ NVITOP 1.5.0      Driver Version: 550.127.08      CUDA Driver Version: 12.4 │
├───────────────────────────────┬──────────────────────┬──────────────────────┤
│ GPU  Name        Persistence-M│ Bus-Id        Disp.A │ MIG M.   Uncorr. ECC │
│ Fan  Temp  Perf  Pwr:Usage/Cap│         Memory-Usage │ GPU-Util  Compute M. │
╞═══════════════════════════════╪══════════════════════╪══════════════════════╪════════════════════════╕
│   0  A100-SXM4-80GB      On   │ 00000000:16:00.0 Off │ Disabled           0 │ MEM: ▏ 0.0%            │
│ N/A   34C    P0    60W / 400W │  16.94MiB / 80.00GiB │      0%      Default │ UTL: ▏ 0%              │
├───────────────────────────────┼──────────────────────┼──────────────────────┼────────────────────────┤
│   1  A100-SXM4-80GB      On   │ 00000000:27:00.0 Off │ Disabled           0 │ MEM: ▏ 0.0%            │
│ N/A   35C    P0    78W / 400W │  16.94MiB / 80.00GiB │      0%      Default │ UTL: ▏ 0%              │
├───────────────────────────────┼──────────────────────┼──────────────────────┼────────────────────────┤
│   2  A100-SXM4-80GB      On   │ 00000000:A8:00.0 Off │ Disabled           0 │ MEM: ▏ 0.0%            │
│ N/A   35C    P0    75W / 400W │  16.94MiB / 80.00GiB │      0%      Default │ UTL: ▏ 0%              │
├───────────────────────────────┼──────────────────────┼──────────────────────┼────────────────────────┤
│   3  A100-SXM4-80GB      On   │ 00000000:B8:00.0 Off │ Disabled           0 │ MEM: ▏ 0.0%            │
│ N/A   33C    P0    61W / 400W │  16.94MiB / 80.00GiB │      0%      Default │ UTL: ▏ 0%              │
╘═══════════════════════════════╧══════════════════════╧══════════════════════╧════════════════════════╛
[ CPU: ██▏ 1.5%                                 UPTIME: 7.7 days ]  ( Load Average:  3.95  2.28  1.87 )
[ MEM: ██▌ 1.7%                                    USED: 6.07GiB ]  [ SWP: ▏ 0.0%                     ]

╒══════════════════════════════════════════════════════════════════════════════════════════════════════╕
│ Processes:                                                                                 user@user │
│ GPU     PID      USER  GPU-MEM %SM %GMBW  %CPU  %MEM      TIME  COMMAND                              │
╘══════════════════════════════════════════════════════════════════════════════════════════════════════╛
```





---



## 先决条件

- [端口要求](https://docs.gpustack.ai/latest/installation/installation-requirements/#port-requirements)
- llama-box 后端的 CPU 支持：带有 AVX2 的 AMD64，或带有 NEON 的 ARM64

检查CPU是否受支持：

[AMD64](https://docs.gpustack.ai/latest/installation/nvidia-cuda/air-gapped-installation/#__tabbed_2_1)[ARM64](https://docs.gpustack.ai/latest/installation/nvidia-cuda/air-gapped-installation/#__tabbed_2_2)

```bash
lscpu | grep avx2
```



- [NVIDIA 驱动程序](https://www.nvidia.com/en-us/drivers/)

检查NVIDIA驱动程序是否已安装：

```bash
nvidia-smi --format=csv,noheader --query-gpu=index,name,memory.total,memory.used,utilization.gpu,temperature.gpu
```

``` bash
# 输出
0, NVIDIA A100-SXM4-80GB, 81920 MiB, 64823 MiB, 0 %, 32
1, NVIDIA A100-SXM4-80GB, 81920 MiB, 64823 MiB, 0 %, 33
2, NVIDIA A100-SXM4-80GB, 81920 MiB, 64823 MiB, 0 %, 34
3, NVIDIA A100-SXM4-80GB, 81920 MiB, 60329 MiB, 0 %, 32
```



并确保驱动程序支持 CUDA 12.4 或更高版本：

[Linux](https://docs.gpustack.ai/latest/installation/nvidia-cuda/air-gapped-installation/#__tabbed_3_1)[视窗](https://docs.gpustack.ai/latest/installation/nvidia-cuda/air-gapped-installation/#__tabbed_3_2)

```bash
nvidia-smi | grep "CUDA Version"
```

``` bash
# 输出
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
```





---



## Docker 安装

### 先决条件

- [Docker](https://docs.docker.com/engine/install/)

- [安装Nvidia驱动](https://www.nvidia.com/en-us/drivers/)

  - ![](images/gpustack_01.png)  
  - 找到对应的驱动型号
  - ![](images/gpustack_02.png)
  - ![](images/gpustack_03.png)  

- #### 安装驱动

  - ``` bash
    (base) user@user:~$ ll | grep nvidia-driver-local
    -rw-rw-r--  1 user user  393969234  5月 16 09:17 nvidia-driver-local-repo-ubuntu2204-550.127.05_1.0-1_amd64.deb
    
    
    sudo cp /var/nvidia-driver-local-repo-ubuntu2204-550.127.05/nvidia-driver-local-819869DA-keyring.gpg /usr/share/keyrings/
    
    
    sudo dpkg -i nvidia-driver-local-repo-ubuntu2204-550.127.05_1.0-1_amd64.deb
    (正在读取数据库 ... 系统当前共安装有 180772 个文件和目录。)
    准备解压 nvidia-driver-local-repo-ubuntu2204-550.127.05_1.0-1_amd64.deb  ...
    正在解压 nvidia-driver-local-repo-ubuntu2204-550.127.05 (1.0-1) 并覆盖 (1.0-1) ...
    正在设置 nvidia-driver-local-repo-ubuntu2204-550.127.05 (1.0-1) ...
    
    ```

- 安装容器工具包

  - 离线安装 NVIDIA 容器工具包（推荐）

    - [nvidia-docker-ubuntu_libs.tar](http://qiniu.dev-share.top/file/nvidia-docker-ubuntu_libs.tar) 

    - ``` bash
  Fri May 16 08:59:23 2025
      ╒═════════════════════════════════════════════════════════════════════════════╕
      │ NVITOP 1.5.0      Driver Version: 550.127.08      CUDA Driver Version: 12.4 │
      ├───────────────────────────────┬──────────────────────┬──────────────────────┤
      │ GPU  Name        Persistence-M│ Bus-Id        Disp.A │ MIG M.   Uncorr. ECC │
      │ Fan  Temp  Perf  Pwr:Usage/Cap│         Memory-Usage │ GPU-Util  Compute M. │
      ╞═══════════════════════════════╪══════════════════════╪══════════════════════╪════════════════════════╕
      │   0  A100-SXM4-80GB      On   │ 00000000:16:00.0 Off │ Disabled           0 │ MEM: ▏ 0.0%             │
      │ N/A   34C    P0    60W / 400W │  16.94MiB / 80.00GiB │      0%      Default │ UTL: ▏ 0%               │
      ├───────────────────────────────┼──────────────────────┼──────────────────────┼────────────────────────┤
      │   1  A100-SXM4-80GB      On   │ 00000000:27:00.0 Off │ Disabled           0 │ MEM: ▏ 0.0%             │
      │ N/A   35C    P0    78W / 400W │  16.94MiB / 80.00GiB │      0%      Default │ UTL: ▏ 0%               │
      ├───────────────────────────────┼──────────────────────┼──────────────────────┼────────────────────────┤
      │   2  A100-SXM4-80GB      On   │ 00000000:A8:00.0 Off │ Disabled           0 │ MEM: ▏ 0.0%             │
      │ N/A   35C    P0    75W / 400W │  16.94MiB / 80.00GiB │      0%      Default │ UTL: ▏ 0%               │
      ├───────────────────────────────┼──────────────────────┼──────────────────────┼────────────────────────┤
      │   3  A100-SXM4-80GB      On   │ 00000000:B8:00.0 Off │ Disabled           0 │ MEM: ▏ 0.0%             │
      │ N/A   33C    P0    61W / 400W │  16.94MiB / 80.00GiB │      0%      Default │ UTL: ▏ 0%               │
      ╘═══════════════════════════════╧══════════════════════╧══════════════════════╧════════════════════════╛
      [ CPU: ██▏ 1.5%                                 UPTIME: 7.7 days ]  ( Load Average:  3.95  2.28  1.87 )
      [ MEM: ██▌ 1.7%                                    USED: 6.07GiB ]  [ SWP: ▏ 0.0%                     ]
      
      ╒══════════════════════════════════════════════════════════════════════════════════════════════════════╕
      │ Processes:                                                                                 user@user │
      │ GPU     PID      USER  GPU-MEM %SM %GMBW  %CPU  %MEM      TIME  COMMAND                              │
      ╘══════════════════════════════════════════════════════════════════════════════════════════════════════╛
      
      
      
      # 解压
      tar -xvf nvidia-docker-ubuntu_libs.tar
      
      
      
      # 按照顺序装
      sudo dpkg -i libnvidia-container1_1.4.0-1_amd64.deb
      sudo dpkg -i libnvidia-container-tools_1.4.0-1_amd64.deb
      sudo dpkg -i nvidia-container-toolkit_1.5.1-1_amd64.deb
      sudo dpkg -i nvidia-container-runtime_3.5.0-1_amd64.deb
      sudo dpkg -i nvidia-docker2_2.6.0-1_all.deb
      
      
      ```
    
    - 

  - [在线安装 NVIDIA 容器工具包](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/release-notes.html#toolkit-container-1-7-0)

- [在 Docker 中禁用 Systemd Cgroup 管理](https://github.com/NVIDIA/nvidia-container-toolkit/issues/48)



> 当使用 systemd 管理容器的 cgroup 并触发重新加载任何引用 NVIDIA GPU 的单元文件（例如 systemctl daemon-reload）时，容器化的 GPU 工作负载可能会突然失去对其 GPU 的访问权限。

在 GPUStack 中，GPU 可能会在资源菜单中丢失，并且`nvidia-smi`在 GPUStack 容器内运行可能会导致以下错误：`Failed to initialize NVML: Unknown Error`

为了防止[出现此问题](https://github.com/NVIDIA/nvidia-container-toolkit/issues/48)，需要在 Docker 中禁用 systemd cgroup 管理。

在文件中设置参数“exec-opts”:[“native.cgroupdriver=cgroupfs”]`/etc/docker/daemon.json`并重启docker，如：

```bash
vim /etc/docker/daemon.json
{
  "runtimes": {
    "nvidia": {
      "args": [],
      "path": "nvidia-container-runtime"
    }
  },
  "exec-opts": ["native.cgroupdriver=cgroupfs"]
}


systemctl daemon-reload && systemctl restart docker
```

检查 Docker 和 NVIDIA Container Toolkit 是否已安装：

```bash
docker info | grep Runtimes | grep nvidia

root@user:~# docker info | grep Runtimes | grep nvidia
 Runtimes: io.containerd.runc.v2 nvidia runc

```



> #### 检查当前使用的是 cgroup v1 还是 v2：
>
> ```
> stat -fc %T /sys/fs/cgroup/
> ```
>
> - 输出为 `cgroup2fs`：说明是 cgroup v2
> - 输出为 `tmpfs` 或 `cgroup`：说明是 cgroup v1
>
> #### 如果是 cgroup v2，可以尝试重启内核为 cgroup v1 模式（⚠️需要修改 grub，重启机器）：
>
> - 编辑 grub 配置：
>
> ```
> sudo vim /etc/default/grub
> ```
>
> - 修改或添加下面这行：
>
> ```
> GRUB_CMDLINE_LINUX="systemd.unified_cgroup_hierarchy=0"
> ```
>
> - 更新 grub：
>
> ```
> sudo update-grub
> ```
>
> - 重启系统(必须重启系统)：
>
> ```
> sudo reboot
> ```



#### 测试-在容器中使用GPU

``` bash
# 从阿里去拉取镜像
docker pull registry.cn-qingdao.aliyuncs.com/cn-aliyun/cuda:12.2.0-base-ubuntu22.04
# 重命名
docker tag registry.cn-qingdao.aliyuncs.com/cn-aliyun/cuda:12.2.0-base-ubuntu22.04 nvidia/cuda:12.2.0-base-ubuntu22.04

# 执行测试
docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi
```

``` bash
Wed May 21 01:03:41 2025
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:16:00.0 Off |                    0 |
| N/A   33C    P0             43W /  400W |     437MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:27:00.0 Off |                    0 |
| N/A   33C    P0             53W /  400W |     437MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:A8:00.0 Off |                    0 |
| N/A   34C    P0             55W /  400W |     437MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:B8:00.0 Off |                    0 |
| N/A   32C    P0             47W /  400W |   54437MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

```



---



## 启动-主节点

#### docker-compose.yaml

``` yaml
# 定义 Docker Compose 文件版本
version: '3.8'

# 服务定义
services:
  gpustack:
    # 使用的 Docker 镜像
    image: gpustack/gpustack
    # 容器名称
    container_name: gpustack
    # 重启策略：除非手动停止，否则自动重启
    restart: unless-stopped

    # GPU 资源配置（需要 NVIDIA Docker 支持）
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia       # 使用 NVIDIA 驱动
              count: all           # 使用所有可用的 GPU
              capabilities: [gpu]  # 启用 GPU 计算能力

    # 网络模式：使用主机网络（与宿主机共享网络栈）
    network_mode: host
    # IPC 模式：使用主机 IPC（进程间通信）
    ipc: host

	# 关闭 seccomp 安全限制，让容器可以使用所有系统调用。
	# 🔹 作用：关闭 seccomp 安全限制，让容器可以使用所有系统调用。
	# 🔹 用途：解决 OpenBLAS、PyTorch 等程序因 seccomp 限制而报错的问题。
	# 🔹 风险：降低容器安全性，不推荐在生产环境使用。
    security_opt:
      - seccomp:unconfined

    # 数据卷挂载（本地目录映射到容器内）
    volumes:
      - ./volumes/gpustack-data:/var/lib/gpustack # 模型默认存储目录为 /var/lib/gpustack/cache，或使用 --cache-dir（优先）、--data-dir 指定的目录。

    environment:
      HF_ENDPOINT: "https://hf-mirror.com"

    command: [
      "--host", "0.0.0.0",                           # 主节点IP
      "--port", "9008",                              # 主节点端口
#      "--disable-worker",                            # 禁止启动主节点时，启动工作节点
      "--worker-name", "worker-01",                  # 工作节点名称
      "--worker-ip", "10.14.153.70",                 # 工作节点IP（需与宿主机一致）
      "--worker-port", "10150",                      # 工作节点端口
      "--metrics-port", "10151"                      # 工作节点指标端口
    ]
```

``` bash
(base) user@user:/data1/deploy/siyu.mao$ docker-compose up -d
Creating gpustack ... done




(base) user@user:/data1/deploy/siyu.mao$ docker-compose ps
  Name                Command               State   Ports
---------------------------------------------------------
gpustack   tini -- gpustack start --p ...   Up




(base) user@user:/data1/deploy/siyu.mao$ docker-compose logs -f
Attaching to gpustack
gpustack    | 2025-05-21T06:05:11+00:00 - gpustack.cmd.start - INFO - GPUStack version: v0.6.1 (a6f90c0)
gpustack    | 2025-05-21T06:05:11+00:00 - gpustack.server.server - INFO - Starting GPUStack server.
gpustack    | 2025-05-21T06:05:11+00:00 - gpustack.server.server - INFO - Running database migration.
gpustack    | 2025-05-21T06:05:11+00:00 - gpustack.server.server - INFO - Database migration completed.
gpustack    | 2025-05-21T06:05:18+00:00 - gpustack.server.server - INFO - Serving on 0.0.0.0:9008.
gpustack    | 2025-05-21T06:05:18+00:00 - gpustack.scheduler.scheduler - INFO - Scheduler started.

gpustack    | 2025-05-21T06:05:22+00:00 - gpustack.worker.worker - INFO - Starting GPUStack worker.
gpustack    | 2025-05-21T06:05:22+00:00 - gpustack.worker.worker_manager - INFO - Registering worker: worker-01
gpustack    | 2025-05-21T06:05:22+00:00 - gpustack.worker.worker - INFO - Serving worker APIs on 0.0.0.0:10150.
gpustack    | 2025-05-21T06:05:22+00:00 - gpustack.worker.serve_manager - INFO - Started watching model instances.
gpustack    | 2025-05-21T06:05:22+00:00 - gpustack.worker.exporter - INFO - Serving metric exporter on 0.0.0.0:10151.
gpustack    | 2025-05-21T06:05:25+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 0 on port 40090, pid 240
gpustack    | 2025-05-21T06:05:25+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 1 on port 40065, pid 241
gpustack    | 2025-05-21T06:05:25+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 2 on port 40092, pid 242
gpustack    | 2025-05-21T06:05:25+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 3 on port 40082, pid 243

```



### 浏览器访问

![](images/gpustack_04.png) 

默认用户名：admin

获取默认密码：`docker exec -it gpustack cat /var/lib/gpustack/initial_admin_password`

![](images/gpustack_05.png) 



---



## 扩展-工作节点(可选)

> 主节点启动时，默认会有一个工作节点，扩展的工作节点要在不同的机器上部署
>
> [启动参数文档](https://docs.gpustack.ai/latest/cli-reference/start/?h=10150#config-file)

#### 获取主节点token

``` bash
docker exec -it gpustack cat /var/lib/gpustack/token

d09745914d9f927a351ab1b94c344ad7
```

#### docker-compose-worker-02.yaml

``` yaml
version: '3.8'

services:
  gpustack-worker-02:
    image: gpustack/gpustack
    container_name: gpustack-worker-02
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    network_mode: host
    ipc: host
    volumes:
      - ./volumes/gpustack-data:/var/lib/gpustack
    environment:
      HF_ENDPOINT: "https://hf-mirror.com"
    command: [
      "--worker-name", "worker-02",                  # 工作节点名称
      "--server-url", "http://10.14.153.70:9008",    # 主节点API地址
      "--token", "d09745914d9f927a351ab1b94c344ad7", # 主节点鉴权令牌
      "--worker-ip", "10.14.153.70",                 # 工作节点IP（需与宿主机一致）
      "--worker-port", "20150",                      # 工作节点端口
      "--metrics-port", "20151"                      # 工作节点指标端口
    ]

```

``` bash
Attaching to gpustack-worker-02
gpustack-worker-02    | 2025-05-21T06:07:34+00:00 - gpustack.cmd.start - INFO - GPUStack version: v0.6.1 (a6f90c0)
gpustack-worker-02    | 2025-05-21T06:07:34+00:00 - gpustack.worker.worker - INFO - Starting GPUStack worker.
gpustack-worker-02    | 2025-05-21T06:07:34+00:00 - gpustack.worker.worker_manager - INFO - Registering worker: worker-02
gpustack-worker-02    | 2025-05-21T06:07:34+00:00 - gpustack.worker.worker_manager - INFO - Worker worker-02 registered.
gpustack-worker-02    | 2025-05-21T06:07:35+00:00 - gpustack.worker.worker - INFO - Serving worker APIs on 0.0.0.0:20150.
gpustack-worker-02    | 2025-05-21T06:07:35+00:00 - gpustack.worker.serve_manager - INFO - Started watching model instances.
gpustack-worker-02    | 2025-05-21T06:07:35+00:00 - gpustack.worker.exporter - INFO - Serving metric exporter on 0.0.0.0:20151.
gpustack-worker-02    | 2025-05-21T06:07:38+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 0 on port 40095, pid 163
gpustack-worker-02    | 2025-05-21T06:07:38+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 1 on port 40079, pid 164
gpustack-worker-02    | 2025-05-21T06:07:38+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 2 on port 40083, pid 165
gpustack-worker-02    | 2025-05-21T06:07:38+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 3 on port 40093, pid 166

```



![](images/gpustack_06.png) 



---



# 部署模型

#### 下载模型

![](images/gpustack_07.png)

#### 部署模型

![](images/gpustack_08.png)   

 

![](images/gpustack_09.png) 

![](images/gpustack_10.png)

![](images/gpustack_11.png)

![](images/gpustack_12.png)

 

#### 手动指定模型所在的Worker，需要重新启动模型

![](images/gpustack_13.png) 







---

# 其它自定义[定义化内容]



### 构建您自己的 Docker 镜像

例如，官方 GPUStack NVIDIA CUDA 镜像是基于 CUDA 12.4 构建的。如果您想使用其他 CUDA 版本，可以构建自己的 Docker 镜像。

```dockerfile
# Example Dockerfile
ARG CUDA_VERSION=12.4.1

FROM nvidia/cuda:$CUDA_VERSION-cudnn-runtime-ubuntu22.04

ARG TARGETPLATFORM
ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update && apt-get install -y \
    git \
    curl \
    wget \
    tzdata \
    iproute2 \
    python3 \
    python3-pip \
    python3-venv \
    && rm -rf /var/lib/apt/lists/*

COPY . /workspace/gpustack
RUN cd /workspace/gpustack && \
    make build

RUN if [ "$TARGETPLATFORM" = "linux/amd64" ]; then \
    # Install vllm dependencies for x86_64
    WHEEL_PACKAGE="$(ls /workspace/gpustack/dist/*.whl)[all]"; \
    else  \
    WHEEL_PACKAGE="$(ls /workspace/gpustack/dist/*.whl)[audio]"; \
    fi && \
    pip install pipx && \
    pip install $WHEEL_PACKAGE && \
    pip cache purge && \
    rm -rf /workspace/gpustack

RUN gpustack download-tools

ENTRYPOINT [ "gpustack", "start" ]
```

运行以下命令构建 Docker 镜像：

```bash
docker build -t gpustack:cuda-12.8 --build-arg CUDA_VERSION=12.8.1 .
```