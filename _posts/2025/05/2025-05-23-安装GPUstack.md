---
title: "å®‰è£…GPUstack"
date: "2025-05-23"
categories: 
  - "GPUstack"
---

# å®‰è£…GPUstack



## ç³»ç»Ÿ

| å‘è¡Œç‰ˆ           | å‘è¡Œç‰ˆä»£ç  | ç¡¬ä»¶æ¶æ„ | æ‰©å±•æ¶æ„ |
| ---------------- | ---------- | -------- | -------- |
| Ubuntu 22.04 LTS | ubuntu2204 | x86_64   | amd64    |



---



## æ˜¾å¡ä¿¡æ¯

``` bash
Fri May 16 08:59:23 2025
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ NVITOP 1.5.0      Driver Version: 550.127.08      CUDA Driver Version: 12.4 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GPU  Name        Persistence-Mâ”‚ Bus-Id        Disp.A â”‚ MIG M.   Uncorr. ECC â”‚
â”‚ Fan  Temp  Perf  Pwr:Usage/Capâ”‚         Memory-Usage â”‚ GPU-Util  Compute M. â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚   0  A100-SXM4-80GB      On   â”‚ 00000000:16:00.0 Off â”‚ Disabled           0 â”‚ MEM: â– 0.0%            â”‚
â”‚ N/A   34C    P0    60W / 400W â”‚  16.94MiB / 80.00GiB â”‚      0%      Default â”‚ UTL: â– 0%              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   1  A100-SXM4-80GB      On   â”‚ 00000000:27:00.0 Off â”‚ Disabled           0 â”‚ MEM: â– 0.0%            â”‚
â”‚ N/A   35C    P0    78W / 400W â”‚  16.94MiB / 80.00GiB â”‚      0%      Default â”‚ UTL: â– 0%              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   2  A100-SXM4-80GB      On   â”‚ 00000000:A8:00.0 Off â”‚ Disabled           0 â”‚ MEM: â– 0.0%            â”‚
â”‚ N/A   35C    P0    75W / 400W â”‚  16.94MiB / 80.00GiB â”‚      0%      Default â”‚ UTL: â– 0%              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   3  A100-SXM4-80GB      On   â”‚ 00000000:B8:00.0 Off â”‚ Disabled           0 â”‚ MEM: â– 0.0%            â”‚
â”‚ N/A   33C    P0    61W / 400W â”‚  16.94MiB / 80.00GiB â”‚      0%      Default â”‚ UTL: â– 0%              â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›
[ CPU: â–ˆâ–ˆâ– 1.5%                                 UPTIME: 7.7 days ]  ( Load Average:  3.95  2.28  1.87 )
[ MEM: â–ˆâ–ˆâ–Œ 1.7%                                    USED: 6.07GiB ]  [ SWP: â– 0.0%                     ]

â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Processes:                                                                                 user@user â”‚
â”‚ GPU     PID      USER  GPU-MEM %SM %GMBW  %CPU  %MEM      TIME  COMMAND                              â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›
```





---



## å…ˆå†³æ¡ä»¶

- [ç«¯å£è¦æ±‚](https://docs.gpustack.ai/latest/installation/installation-requirements/#port-requirements)
- llama-box åç«¯çš„ CPU æ”¯æŒï¼šå¸¦æœ‰ AVX2 çš„ AMD64ï¼Œæˆ–å¸¦æœ‰ NEON çš„ ARM64

æ£€æŸ¥CPUæ˜¯å¦å—æ”¯æŒï¼š

[AMD64](https://docs.gpustack.ai/latest/installation/nvidia-cuda/air-gapped-installation/#__tabbed_2_1)[ARM64](https://docs.gpustack.ai/latest/installation/nvidia-cuda/air-gapped-installation/#__tabbed_2_2)

```bash
lscpu | grep avx2
```



- [NVIDIA é©±åŠ¨ç¨‹åº](https://www.nvidia.com/en-us/drivers/)

æ£€æŸ¥NVIDIAé©±åŠ¨ç¨‹åºæ˜¯å¦å·²å®‰è£…ï¼š

```bash
nvidia-smi --format=csv,noheader --query-gpu=index,name,memory.total,memory.used,utilization.gpu,temperature.gpu
```

``` bash
# è¾“å‡º
0, NVIDIA A100-SXM4-80GB, 81920 MiB, 64823 MiB, 0 %, 32
1, NVIDIA A100-SXM4-80GB, 81920 MiB, 64823 MiB, 0 %, 33
2, NVIDIA A100-SXM4-80GB, 81920 MiB, 64823 MiB, 0 %, 34
3, NVIDIA A100-SXM4-80GB, 81920 MiB, 60329 MiB, 0 %, 32
```



å¹¶ç¡®ä¿é©±åŠ¨ç¨‹åºæ”¯æŒ CUDA 12.4 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼š

[Linux](https://docs.gpustack.ai/latest/installation/nvidia-cuda/air-gapped-installation/#__tabbed_3_1)[è§†çª—](https://docs.gpustack.ai/latest/installation/nvidia-cuda/air-gapped-installation/#__tabbed_3_2)

```bash
nvidia-smi | grep "CUDA Version"
```

``` bash
# è¾“å‡º
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
```





---



## Docker å®‰è£…

### å…ˆå†³æ¡ä»¶

- [Docker](https://docs.docker.com/engine/install/)

- [å®‰è£…Nvidiaé©±åŠ¨](https://www.nvidia.com/en-us/drivers/)

  - ![](images/gpustack_01.png)  
  - æ‰¾åˆ°å¯¹åº”çš„é©±åŠ¨å‹å·
  - ![](images/gpustack_02.png)
  - ![](images/gpustack_03.png)  

- #### å®‰è£…é©±åŠ¨

  - ``` bash
    (base) user@user:~$ ll | grep nvidia-driver-local
    -rw-rw-r--  1 user user  393969234  5æœˆ 16 09:17 nvidia-driver-local-repo-ubuntu2204-550.127.05_1.0-1_amd64.deb
    
    
    sudo cp /var/nvidia-driver-local-repo-ubuntu2204-550.127.05/nvidia-driver-local-819869DA-keyring.gpg /usr/share/keyrings/
    
    
    sudo dpkg -i nvidia-driver-local-repo-ubuntu2204-550.127.05_1.0-1_amd64.deb
    (æ­£åœ¨è¯»å–æ•°æ®åº“ ... ç³»ç»Ÿå½“å‰å…±å®‰è£…æœ‰ 180772 ä¸ªæ–‡ä»¶å’Œç›®å½•ã€‚)
    å‡†å¤‡è§£å‹ nvidia-driver-local-repo-ubuntu2204-550.127.05_1.0-1_amd64.deb  ...
    æ­£åœ¨è§£å‹ nvidia-driver-local-repo-ubuntu2204-550.127.05 (1.0-1) å¹¶è¦†ç›– (1.0-1) ...
    æ­£åœ¨è®¾ç½® nvidia-driver-local-repo-ubuntu2204-550.127.05 (1.0-1) ...
    
    ```

- å®‰è£…å®¹å™¨å·¥å…·åŒ…

  - ç¦»çº¿å®‰è£… NVIDIA å®¹å™¨å·¥å…·åŒ…ï¼ˆæ¨èï¼‰

    - [nvidia-docker-ubuntu_libs.tar](http://qiniu.dev-share.top/file/nvidia-docker-ubuntu_libs.tar) 

    - ``` bash
  Fri May 16 08:59:23 2025
      â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
      â”‚ NVITOP 1.5.0      Driver Version: 550.127.08      CUDA Driver Version: 12.4 â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚ GPU  Name        Persistence-Mâ”‚ Bus-Id        Disp.A â”‚ MIG M.   Uncorr. ECC â”‚
      â”‚ Fan  Temp  Perf  Pwr:Usage/Capâ”‚         Memory-Usage â”‚ GPU-Util  Compute M. â”‚
      â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
      â”‚   0  A100-SXM4-80GB      On   â”‚ 00000000:16:00.0 Off â”‚ Disabled           0 â”‚ MEM: â– 0.0%             â”‚
      â”‚ N/A   34C    P0    60W / 400W â”‚  16.94MiB / 80.00GiB â”‚      0%      Default â”‚ UTL: â– 0%               â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚   1  A100-SXM4-80GB      On   â”‚ 00000000:27:00.0 Off â”‚ Disabled           0 â”‚ MEM: â– 0.0%             â”‚
      â”‚ N/A   35C    P0    78W / 400W â”‚  16.94MiB / 80.00GiB â”‚      0%      Default â”‚ UTL: â– 0%               â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚   2  A100-SXM4-80GB      On   â”‚ 00000000:A8:00.0 Off â”‚ Disabled           0 â”‚ MEM: â– 0.0%             â”‚
      â”‚ N/A   35C    P0    75W / 400W â”‚  16.94MiB / 80.00GiB â”‚      0%      Default â”‚ UTL: â– 0%               â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚   3  A100-SXM4-80GB      On   â”‚ 00000000:B8:00.0 Off â”‚ Disabled           0 â”‚ MEM: â– 0.0%             â”‚
      â”‚ N/A   33C    P0    61W / 400W â”‚  16.94MiB / 80.00GiB â”‚      0%      Default â”‚ UTL: â– 0%               â”‚
      â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›
      [ CPU: â–ˆâ–ˆâ– 1.5%                                 UPTIME: 7.7 days ]  ( Load Average:  3.95  2.28  1.87 )
      [ MEM: â–ˆâ–ˆâ–Œ 1.7%                                    USED: 6.07GiB ]  [ SWP: â– 0.0%                     ]
      
      â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••
      â”‚ Processes:                                                                                 user@user â”‚
      â”‚ GPU     PID      USER  GPU-MEM %SM %GMBW  %CPU  %MEM      TIME  COMMAND                              â”‚
      â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›
      
      
      
      # è§£å‹
      tar -xvf nvidia-docker-ubuntu_libs.tar
      
      
      
      # æŒ‰ç…§é¡ºåºè£…
      sudo dpkg -i libnvidia-container1_1.4.0-1_amd64.deb
      sudo dpkg -i libnvidia-container-tools_1.4.0-1_amd64.deb
      sudo dpkg -i nvidia-container-toolkit_1.5.1-1_amd64.deb
      sudo dpkg -i nvidia-container-runtime_3.5.0-1_amd64.deb
      sudo dpkg -i nvidia-docker2_2.6.0-1_all.deb
      
      
      ```
    
    - 

  - [åœ¨çº¿å®‰è£… NVIDIA å®¹å™¨å·¥å…·åŒ…](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/release-notes.html#toolkit-container-1-7-0)

- [åœ¨ Docker ä¸­ç¦ç”¨ Systemd Cgroup ç®¡ç†](https://github.com/NVIDIA/nvidia-container-toolkit/issues/48)



> å½“ä½¿ç”¨ systemd ç®¡ç†å®¹å™¨çš„ cgroup å¹¶è§¦å‘é‡æ–°åŠ è½½ä»»ä½•å¼•ç”¨ NVIDIA GPU çš„å•å…ƒæ–‡ä»¶ï¼ˆä¾‹å¦‚ systemctl daemon-reloadï¼‰æ—¶ï¼Œå®¹å™¨åŒ–çš„ GPU å·¥ä½œè´Ÿè½½å¯èƒ½ä¼šçªç„¶å¤±å»å¯¹å…¶ GPU çš„è®¿é—®æƒé™ã€‚

åœ¨ GPUStack ä¸­ï¼ŒGPU å¯èƒ½ä¼šåœ¨èµ„æºèœå•ä¸­ä¸¢å¤±ï¼Œå¹¶ä¸”`nvidia-smi`åœ¨ GPUStack å®¹å™¨å†…è¿è¡Œå¯èƒ½ä¼šå¯¼è‡´ä»¥ä¸‹é”™è¯¯ï¼š`Failed to initialize NVML: Unknown Error`

ä¸ºäº†é˜²æ­¢[å‡ºç°æ­¤é—®é¢˜](https://github.com/NVIDIA/nvidia-container-toolkit/issues/48)ï¼Œéœ€è¦åœ¨ Docker ä¸­ç¦ç”¨ systemd cgroup ç®¡ç†ã€‚

åœ¨æ–‡ä»¶ä¸­è®¾ç½®å‚æ•°â€œexec-optsâ€:[â€œnative.cgroupdriver=cgroupfsâ€]`/etc/docker/daemon.json`å¹¶é‡å¯dockerï¼Œå¦‚ï¼š

```bash
vim /etc/docker/daemon.json
{
  "runtimes": {
    "nvidia": {
      "args": [],
      "path": "nvidia-container-runtime"
    }
  },
  "exec-opts": ["native.cgroupdriver=cgroupfs"]
}


systemctl daemon-reload && systemctl restart docker
```

æ£€æŸ¥ Docker å’Œ NVIDIA Container Toolkit æ˜¯å¦å·²å®‰è£…ï¼š

```bash
docker info | grep Runtimes | grep nvidia

root@user:~# docker info | grep Runtimes | grep nvidia
 Runtimes: io.containerd.runc.v2 nvidia runc

```



> #### æ£€æŸ¥å½“å‰ä½¿ç”¨çš„æ˜¯ cgroup v1 è¿˜æ˜¯ v2ï¼š
>
> ```
> stat -fc %T /sys/fs/cgroup/
> ```
>
> - è¾“å‡ºä¸º `cgroup2fs`ï¼šè¯´æ˜æ˜¯ cgroup v2
> - è¾“å‡ºä¸º `tmpfs` æˆ– `cgroup`ï¼šè¯´æ˜æ˜¯ cgroup v1
>
> #### å¦‚æœæ˜¯ cgroup v2ï¼Œå¯ä»¥å°è¯•é‡å¯å†…æ ¸ä¸º cgroup v1 æ¨¡å¼ï¼ˆâš ï¸éœ€è¦ä¿®æ”¹ grubï¼Œé‡å¯æœºå™¨ï¼‰ï¼š
>
> - ç¼–è¾‘ grub é…ç½®ï¼š
>
> ```
> sudo vim /etc/default/grub
> ```
>
> - ä¿®æ”¹æˆ–æ·»åŠ ä¸‹é¢è¿™è¡Œï¼š
>
> ```
> GRUB_CMDLINE_LINUX="systemd.unified_cgroup_hierarchy=0"
> ```
>
> - æ›´æ–° grubï¼š
>
> ```
> sudo update-grub
> ```
>
> - é‡å¯ç³»ç»Ÿ(å¿…é¡»é‡å¯ç³»ç»Ÿ)ï¼š
>
> ```
> sudo reboot
> ```



#### æµ‹è¯•-åœ¨å®¹å™¨ä¸­ä½¿ç”¨GPU

``` bash
# ä»é˜¿é‡Œå»æ‹‰å–é•œåƒ
docker pull registry.cn-qingdao.aliyuncs.com/cn-aliyun/cuda:12.2.0-base-ubuntu22.04
# é‡å‘½å
docker tag registry.cn-qingdao.aliyuncs.com/cn-aliyun/cuda:12.2.0-base-ubuntu22.04 nvidia/cuda:12.2.0-base-ubuntu22.04

# æ‰§è¡Œæµ‹è¯•
docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi
```

``` bash
Wed May 21 01:03:41 2025
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:16:00.0 Off |                    0 |
| N/A   33C    P0             43W /  400W |     437MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:27:00.0 Off |                    0 |
| N/A   33C    P0             53W /  400W |     437MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:A8:00.0 Off |                    0 |
| N/A   34C    P0             55W /  400W |     437MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:B8:00.0 Off |                    0 |
| N/A   32C    P0             47W /  400W |   54437MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

```



---



## å¯åŠ¨-ä¸»èŠ‚ç‚¹

#### docker-compose.yaml

``` yaml
# å®šä¹‰ Docker Compose æ–‡ä»¶ç‰ˆæœ¬
version: '3.8'

# æœåŠ¡å®šä¹‰
services:
  gpustack:
    # ä½¿ç”¨çš„ Docker é•œåƒ
    image: gpustack/gpustack
    # å®¹å™¨åç§°
    container_name: gpustack
    # é‡å¯ç­–ç•¥ï¼šé™¤éæ‰‹åŠ¨åœæ­¢ï¼Œå¦åˆ™è‡ªåŠ¨é‡å¯
    restart: unless-stopped

    # GPU èµ„æºé…ç½®ï¼ˆéœ€è¦ NVIDIA Docker æ”¯æŒï¼‰
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia       # ä½¿ç”¨ NVIDIA é©±åŠ¨
              count: all           # ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„ GPU
              capabilities: [gpu]  # å¯ç”¨ GPU è®¡ç®—èƒ½åŠ›

    # ç½‘ç»œæ¨¡å¼ï¼šä½¿ç”¨ä¸»æœºç½‘ç»œï¼ˆä¸å®¿ä¸»æœºå…±äº«ç½‘ç»œæ ˆï¼‰
    network_mode: host
    # IPC æ¨¡å¼ï¼šä½¿ç”¨ä¸»æœº IPCï¼ˆè¿›ç¨‹é—´é€šä¿¡ï¼‰
    ipc: host

	# å…³é—­ seccomp å®‰å…¨é™åˆ¶ï¼Œè®©å®¹å™¨å¯ä»¥ä½¿ç”¨æ‰€æœ‰ç³»ç»Ÿè°ƒç”¨ã€‚
	# ğŸ”¹ ä½œç”¨ï¼šå…³é—­ seccomp å®‰å…¨é™åˆ¶ï¼Œè®©å®¹å™¨å¯ä»¥ä½¿ç”¨æ‰€æœ‰ç³»ç»Ÿè°ƒç”¨ã€‚
	# ğŸ”¹ ç”¨é€”ï¼šè§£å†³ OpenBLASã€PyTorch ç­‰ç¨‹åºå›  seccomp é™åˆ¶è€ŒæŠ¥é”™çš„é—®é¢˜ã€‚
	# ğŸ”¹ é£é™©ï¼šé™ä½å®¹å™¨å®‰å…¨æ€§ï¼Œä¸æ¨èåœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ã€‚
    security_opt:
      - seccomp:unconfined

    # æ•°æ®å·æŒ‚è½½ï¼ˆæœ¬åœ°ç›®å½•æ˜ å°„åˆ°å®¹å™¨å†…ï¼‰
    volumes:
      - ./volumes/gpustack-data:/var/lib/gpustack # æ¨¡å‹é»˜è®¤å­˜å‚¨ç›®å½•ä¸º /var/lib/gpustack/cacheï¼Œæˆ–ä½¿ç”¨ --cache-dirï¼ˆä¼˜å…ˆï¼‰ã€--data-dir æŒ‡å®šçš„ç›®å½•ã€‚

    environment:
      HF_ENDPOINT: "https://hf-mirror.com"

    command: [
      "--host", "0.0.0.0",                           # ä¸»èŠ‚ç‚¹IP
      "--port", "9008",                              # ä¸»èŠ‚ç‚¹ç«¯å£
#      "--disable-worker",                            # ç¦æ­¢å¯åŠ¨ä¸»èŠ‚ç‚¹æ—¶ï¼Œå¯åŠ¨å·¥ä½œèŠ‚ç‚¹
      "--worker-name", "worker-01",                  # å·¥ä½œèŠ‚ç‚¹åç§°
      "--worker-ip", "10.14.153.70",                 # å·¥ä½œèŠ‚ç‚¹IPï¼ˆéœ€ä¸å®¿ä¸»æœºä¸€è‡´ï¼‰
      "--worker-port", "10150",                      # å·¥ä½œèŠ‚ç‚¹ç«¯å£
      "--metrics-port", "10151"                      # å·¥ä½œèŠ‚ç‚¹æŒ‡æ ‡ç«¯å£
    ]
```

``` bash
(base) user@user:/data1/deploy/siyu.mao$ docker-compose up -d
Creating gpustack ... done




(base) user@user:/data1/deploy/siyu.mao$ docker-compose ps
  Name                Command               State   Ports
---------------------------------------------------------
gpustack   tini -- gpustack start --p ...   Up




(base) user@user:/data1/deploy/siyu.mao$ docker-compose logs -f
Attaching to gpustack
gpustack    | 2025-05-21T06:05:11+00:00 - gpustack.cmd.start - INFO - GPUStack version: v0.6.1 (a6f90c0)
gpustack    | 2025-05-21T06:05:11+00:00 - gpustack.server.server - INFO - Starting GPUStack server.
gpustack    | 2025-05-21T06:05:11+00:00 - gpustack.server.server - INFO - Running database migration.
gpustack    | 2025-05-21T06:05:11+00:00 - gpustack.server.server - INFO - Database migration completed.
gpustack    | 2025-05-21T06:05:18+00:00 - gpustack.server.server - INFO - Serving on 0.0.0.0:9008.
gpustack    | 2025-05-21T06:05:18+00:00 - gpustack.scheduler.scheduler - INFO - Scheduler started.

gpustack    | 2025-05-21T06:05:22+00:00 - gpustack.worker.worker - INFO - Starting GPUStack worker.
gpustack    | 2025-05-21T06:05:22+00:00 - gpustack.worker.worker_manager - INFO - Registering worker: worker-01
gpustack    | 2025-05-21T06:05:22+00:00 - gpustack.worker.worker - INFO - Serving worker APIs on 0.0.0.0:10150.
gpustack    | 2025-05-21T06:05:22+00:00 - gpustack.worker.serve_manager - INFO - Started watching model instances.
gpustack    | 2025-05-21T06:05:22+00:00 - gpustack.worker.exporter - INFO - Serving metric exporter on 0.0.0.0:10151.
gpustack    | 2025-05-21T06:05:25+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 0 on port 40090, pid 240
gpustack    | 2025-05-21T06:05:25+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 1 on port 40065, pid 241
gpustack    | 2025-05-21T06:05:25+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 2 on port 40092, pid 242
gpustack    | 2025-05-21T06:05:25+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 3 on port 40082, pid 243

```



### æµè§ˆå™¨è®¿é—®

![](images/gpustack_04.png) 

é»˜è®¤ç”¨æˆ·åï¼šadmin

è·å–é»˜è®¤å¯†ç ï¼š`docker exec -it gpustack cat /var/lib/gpustack/initial_admin_password`

![](images/gpustack_05.png) 



---



## æ‰©å±•-å·¥ä½œèŠ‚ç‚¹(å¯é€‰)

> ä¸»èŠ‚ç‚¹å¯åŠ¨æ—¶ï¼Œé»˜è®¤ä¼šæœ‰ä¸€ä¸ªå·¥ä½œèŠ‚ç‚¹ï¼Œæ‰©å±•çš„å·¥ä½œèŠ‚ç‚¹è¦åœ¨ä¸åŒçš„æœºå™¨ä¸Šéƒ¨ç½²
>
> [å¯åŠ¨å‚æ•°æ–‡æ¡£](https://docs.gpustack.ai/latest/cli-reference/start/?h=10150#config-file)

#### è·å–ä¸»èŠ‚ç‚¹token

``` bash
docker exec -it gpustack cat /var/lib/gpustack/token

d09745914d9f927a351ab1b94c344ad7
```

#### docker-compose-worker-02.yaml

``` yaml
version: '3.8'

services:
  gpustack-worker-02:
    image: gpustack/gpustack
    container_name: gpustack-worker-02
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    network_mode: host
    ipc: host
    volumes:
      - ./volumes/gpustack-data:/var/lib/gpustack
    environment:
      HF_ENDPOINT: "https://hf-mirror.com"
    command: [
      "--worker-name", "worker-02",                  # å·¥ä½œèŠ‚ç‚¹åç§°
      "--server-url", "http://10.14.153.70:9008",    # ä¸»èŠ‚ç‚¹APIåœ°å€
      "--token", "d09745914d9f927a351ab1b94c344ad7", # ä¸»èŠ‚ç‚¹é‰´æƒä»¤ç‰Œ
      "--worker-ip", "10.14.153.70",                 # å·¥ä½œèŠ‚ç‚¹IPï¼ˆéœ€ä¸å®¿ä¸»æœºä¸€è‡´ï¼‰
      "--worker-port", "20150",                      # å·¥ä½œèŠ‚ç‚¹ç«¯å£
      "--metrics-port", "20151"                      # å·¥ä½œèŠ‚ç‚¹æŒ‡æ ‡ç«¯å£
    ]

```

``` bash
Attaching to gpustack-worker-02
gpustack-worker-02    | 2025-05-21T06:07:34+00:00 - gpustack.cmd.start - INFO - GPUStack version: v0.6.1 (a6f90c0)
gpustack-worker-02    | 2025-05-21T06:07:34+00:00 - gpustack.worker.worker - INFO - Starting GPUStack worker.
gpustack-worker-02    | 2025-05-21T06:07:34+00:00 - gpustack.worker.worker_manager - INFO - Registering worker: worker-02
gpustack-worker-02    | 2025-05-21T06:07:34+00:00 - gpustack.worker.worker_manager - INFO - Worker worker-02 registered.
gpustack-worker-02    | 2025-05-21T06:07:35+00:00 - gpustack.worker.worker - INFO - Serving worker APIs on 0.0.0.0:20150.
gpustack-worker-02    | 2025-05-21T06:07:35+00:00 - gpustack.worker.serve_manager - INFO - Started watching model instances.
gpustack-worker-02    | 2025-05-21T06:07:35+00:00 - gpustack.worker.exporter - INFO - Serving metric exporter on 0.0.0.0:20151.
gpustack-worker-02    | 2025-05-21T06:07:38+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 0 on port 40095, pid 163
gpustack-worker-02    | 2025-05-21T06:07:38+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 1 on port 40079, pid 164
gpustack-worker-02    | 2025-05-21T06:07:38+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 2 on port 40083, pid 165
gpustack-worker-02    | 2025-05-21T06:07:38+00:00 - gpustack.worker.worker_manager - INFO - Started RPC server for GPU 3 on port 40093, pid 166

```



![](images/gpustack_06.png) 



---



# éƒ¨ç½²æ¨¡å‹

#### ä¸‹è½½æ¨¡å‹

![](images/gpustack_07.png)

#### éƒ¨ç½²æ¨¡å‹

![](images/gpustack_08.png)   

 

![](images/gpustack_09.png) 

![](images/gpustack_10.png)

![](images/gpustack_11.png)

![](images/gpustack_12.png)

 

#### æ‰‹åŠ¨æŒ‡å®šæ¨¡å‹æ‰€åœ¨çš„Workerï¼Œéœ€è¦é‡æ–°å¯åŠ¨æ¨¡å‹

![](images/gpustack_13.png) 







---

# å…¶å®ƒè‡ªå®šä¹‰[å®šä¹‰åŒ–å†…å®¹]



### æ„å»ºæ‚¨è‡ªå·±çš„ Docker é•œåƒ

ä¾‹å¦‚ï¼Œå®˜æ–¹ GPUStack NVIDIA CUDA é•œåƒæ˜¯åŸºäº CUDA 12.4 æ„å»ºçš„ã€‚å¦‚æœæ‚¨æƒ³ä½¿ç”¨å…¶ä»– CUDA ç‰ˆæœ¬ï¼Œå¯ä»¥æ„å»ºè‡ªå·±çš„ Docker é•œåƒã€‚

```dockerfile
# Example Dockerfile
ARG CUDA_VERSION=12.4.1

FROM nvidia/cuda:$CUDA_VERSION-cudnn-runtime-ubuntu22.04

ARG TARGETPLATFORM
ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update && apt-get install -y \
    git \
    curl \
    wget \
    tzdata \
    iproute2 \
    python3 \
    python3-pip \
    python3-venv \
    && rm -rf /var/lib/apt/lists/*

COPY . /workspace/gpustack
RUN cd /workspace/gpustack && \
    make build

RUN if [ "$TARGETPLATFORM" = "linux/amd64" ]; then \
    # Install vllm dependencies for x86_64
    WHEEL_PACKAGE="$(ls /workspace/gpustack/dist/*.whl)[all]"; \
    else  \
    WHEEL_PACKAGE="$(ls /workspace/gpustack/dist/*.whl)[audio]"; \
    fi && \
    pip install pipx && \
    pip install $WHEEL_PACKAGE && \
    pip cache purge && \
    rm -rf /workspace/gpustack

RUN gpustack download-tools

ENTRYPOINT [ "gpustack", "start" ]
```

è¿è¡Œä»¥ä¸‹å‘½ä»¤æ„å»º Docker é•œåƒï¼š

```bash
docker build -t gpustack:cuda-12.8 --build-arg CUDA_VERSION=12.8.1 .
```